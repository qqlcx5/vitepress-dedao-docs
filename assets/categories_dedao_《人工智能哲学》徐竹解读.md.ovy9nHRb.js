import{f as o,D as i,c as l,o as a,a1 as r,b as s,k as p,w as B,a as A,H as n,a2 as e}from"./chunks/framework.Baju3tsf.js";const u=JSON.parse('{"title":"《人工智能哲学》| 徐竹解读","description":"人工智能能否成为心灵本身而不只是心灵的工具，取决于我们如何理解心灵。","frontmatter":{"title":"《人工智能哲学》| 徐竹解读","description":"人工智能能否成为心灵本身而不只是心灵的工具，取决于我们如何理解心灵。","created":"2025-01-18T16:07:10.000Z","modification_date":"2025-01-18T16:07:10.000Z","tags":["科普/人工智能"],"cover_url":"https://piccdn3.umiwi.com/img/201801/31/201801311807158060913209.jpg?x-oss-process=image/resize,m_fill,h_224,w_168","source":"https://www.dedao.cn/audioBook/detail?id=4pM2nxZ9QleJWn1wY0AvP7w6XBERN3&score=4.8&learn_count=8","author":null},"headers":[],"relativePath":"categories/dedao/《人工智能哲学》徐竹解读.md","filePath":"categories/dedao/《人工智能哲学》徐竹解读.md"}'),d={name:"categories/dedao/《人工智能哲学》徐竹解读.md"};function m(h,E,g,F,D,c){const t=i("Mermaid");return a(),l("div",null,[E[3]||(E[3]=r('<h1 id="《人工智能哲学》徐竹解读" tabindex="-1">《人工智能哲学》徐竹解读 <a class="header-anchor" href="#《人工智能哲学》徐竹解读" aria-label="Permalink to &quot;《人工智能哲学》徐竹解读&quot;">​</a></h1><h2 id="可视化总结" tabindex="-1">可视化总结 <a class="header-anchor" href="#可视化总结" aria-label="Permalink to &quot;可视化总结&quot;">​</a></h2><p>#科普/人工智能</p><h2 id="mermaid-流程图" tabindex="-1">Mermaid 流程图 <a class="header-anchor" href="#mermaid-流程图" aria-label="Permalink to &quot;Mermaid 流程图&quot;">​</a></h2>',4)),(a(),s(e,null,{default:B(()=>[n(t,{id:"mermaid-12",class:"mermaid",graph:"graph%20LR%0AA%5B%E7%94%A8%E6%88%B7%E8%BE%93%E5%85%A5%E5%85%B3%E4%BA%8E%E4%BD%9C%E8%80%85%E5%92%8C%E4%B9%A6%E7%B1%8D%E4%BF%A1%E6%81%AF%5D%20--%3E%20B%7B%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%7D%3B%0AB%20--%20%E4%BD%9C%E8%80%85%E4%BF%A1%E6%81%AF%20--%3E%20C%5B%E4%BD%9C%E8%80%85%E7%94%9F%E5%B9%B3%E5%92%8C%E8%91%97%E4%BD%9C%5D%3B%0AB%20--%20%E4%B9%A6%E7%B1%8D%E4%BF%A1%E6%81%AF%20--%3E%20D%5B%E4%B9%A6%E7%B1%8D%E5%86%85%E5%AE%B9%E6%A6%82%E8%A6%81%5D%3B%0AD%20--%3E%20E%5B%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9%E6%8F%90%E5%8F%96%5D%3B%0AE%20--%3E%20F%5B%E6%80%9D%E6%83%B3%E5%AE%9E%E9%AA%8C%EF%BC%9A%E4%B8%AD%E6%96%87%E5%B1%8B%5D%3B%0AF%20--%3E%20G%5B%E5%BC%BA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E5%BC%B1%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%5D%3B%0AG%20--%3E%20H%5B%E7%AC%A6%E5%8F%B7%E4%B8%BB%E4%B9%89%5D%3B%0AH%20--%3E%20I%5B%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89%5D%3B%0AI%20--%3E%20J%5B%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E6%9C%AA%E6%9D%A5%E4%B8%8E%E6%8C%91%E6%88%98%5D%3B%0A"})]),fallback:B(()=>E[0]||(E[0]=[A(" Loading... ")])),_:1})),E[4]||(E[4]=p("h2",{id:"mermaid-状态图",tabindex:"-1"},[A("Mermaid 状态图 "),p("a",{class:"header-anchor",href:"#mermaid-状态图","aria-label":'Permalink to "Mermaid 状态图"'},"​")],-1)),(a(),s(e,null,{default:B(()=>[n(t,{id:"mermaid-16",class:"mermaid",graph:"stateDiagram%0A%5B*%5D%20--%3E%20%E7%AC%A6%E5%8F%B7%E4%B8%BB%E4%B9%89%3A%20%E5%9F%BA%E4%BA%8E%E7%AC%A6%E5%8F%B7%E8%AE%A1%E7%AE%97%0A%E7%AC%A6%E5%8F%B7%E4%B8%BB%E4%B9%89%20--%3E%20%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89%3A%20%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%0A%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89%20--%3E%20%E6%B6%89%E8%BA%AB%E8%AE%A4%E7%9F%A5%3A%20%E8%80%83%E8%99%91%E8%BA%AB%E4%BD%93%E5%AF%B9%E6%99%BA%E8%83%BD%E7%9A%84%E6%84%8F%E4%B9%89%0A%E6%B6%89%E8%BA%AB%E8%AE%A4%E7%9F%A5%20--%3E%20%E6%9C%AA%E6%9D%A5%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%3A%20%E9%80%9A%E7%94%A8%E6%99%BA%E8%83%BD%EF%BC%8C%E6%83%85%E6%84%9F%EF%BC%8C%E8%87%AA%E6%88%91%E6%84%8F%E8%AF%86%0A"})]),fallback:B(()=>E[1]||(E[1]=[A(" Loading... ")])),_:1})),E[5]||(E[5]=p("h2",{id:"mermaid-思维导图",tabindex:"-1"},[A("Mermaid 思维导图 "),p("a",{class:"header-anchor",href:"#mermaid-思维导图","aria-label":'Permalink to "Mermaid 思维导图"'},"​")],-1)),(a(),s(e,null,{default:B(()=>[n(t,{id:"mermaid-20",class:"mermaid",graph:"mindmap%0Aroot((%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%93%B2%E5%AD%A6))%0A%20%20%E5%AD%90%E4%B8%BB%E9%A2%981(%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98)%0A%20%20%20%20%E9%97%AE%E9%A2%981(%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%BA%BA%E7%B1%BB%E6%99%BA%E8%83%BD%3F)%0A%20%20%20%20%20%20%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%8E%A8%E7%90%86%0A%20%20%20%20%20%20%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95%0A%20%20%20%20%E9%97%AE%E9%A2%982(%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%98%AF%E7%AC%A6%E5%8F%B7%E8%AE%A1%E7%AE%97%E5%90%97%3F)%0A%20%20%20%20%20%20%E7%AC%A6%E5%8F%B7%E4%B8%BB%E4%B9%89%0A%20%20%20%20%20%20%E4%BC%98%E7%BC%BA%E7%82%B9%0A%20%20%20%20%E9%97%AE%E9%A2%983(%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E5%90%97%3F)%0A%20%20%20%20%20%20%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89%0A%20%20%20%20%20%20%E4%BC%98%E7%BC%BA%E7%82%B9%0A%20%20%20%20%E9%97%AE%E9%A2%984(%E8%B7%9D%E7%A6%BB%E5%AE%8C%E5%85%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%BF%98%E6%9C%89%E5%A4%9A%E8%BF%9C%3F)%0A%20%20%20%20%20%20%E9%80%9A%E7%94%A8vs.%E4%B8%93%E9%97%A8%0A%20%20%20%20%20%20%E6%83%85%E6%84%9F%E4%B8%8E%E8%87%AA%E6%88%91%E6%84%8F%E8%AF%86%0A%20%20%20%20%20%20%E6%B6%89%E8%BA%AB%E8%AE%A4%E7%9F%A5%0A%20%20%E5%AD%90%E4%B8%BB%E9%A2%982(%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5)%0A%20%20%20%20%E5%BC%BA%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%0A%20%20%20%20%E5%BC%B1%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%0A%20%20%20%20%E4%B8%AD%E6%96%87%E5%B1%8B%0A%20%20%20%20%E7%AC%A6%E5%8F%B7%E4%B8%BB%E4%B9%89%0A%20%20%20%20%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89%0A%20%20%20%20%E6%B6%89%E8%BA%AB%E8%AE%A4%E7%9F%A5%0A%20%20%E5%AD%90%E4%B8%BB%E9%A2%983(%E5%85%B3%E9%94%AE%E4%BA%BA%E7%89%A9)%0A%20%20%20%20%E7%8E%9B%E6%A0%BC%E4%B8%BD%E7%89%B9%C2%B7%E5%8D%9A%E7%99%BB%0A%20%20%20%20%E9%98%BF%E5%85%B0%C2%B7%E5%9B%BE%E7%81%B5%0A%20%20%20%20%E7%BA%A6%E7%BF%B0%C2%B7%E5%A1%9E%E5%B0%94%0A%20%20%20%20%E7%BA%BD%E5%8E%84%E5%B0%94%E5%92%8C%E8%A5%BF%E8%92%99%0A%20%20%20%20%E5%A4%A7%E5%8D%AB%C2%B7%E4%BC%91%E8%B0%9F%0A%20%20%20%20%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E5%BE%B7%E9%9B%B7%E7%A6%8F%E6%96%AF%0A"})]),fallback:B(()=>E[2]||(E[2]=[A(" Loading... ")])),_:1})),E[6]||(E[6]=r(`<h2 id="内容总结" tabindex="-1">内容总结 <a class="header-anchor" href="#内容总结" aria-label="Permalink to &quot;内容总结&quot;">​</a></h2><div class="language-ad-think vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">ad-think</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>嗯，用户让我分析关于《人工智能哲学》这本书的解读内容，需要生成一个思考过程，然后给出回答。首先，我需要理解用户提供的材料。材料详细介绍了玛格丽特·A.博登的著作《人工智能哲学》，包括作者背景、书籍结构、核心内容，以及四个主要问题的讨论：计算机实现的智能类型、符号主义与联结主义的优缺点、现实与理想AI的差距等。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>用户可能的需求是希望得到对这本书的总结，或者深入探讨其中的哲学问题。用户可能对人工智能的哲学基础感兴趣，或者想了解书中提到的关键论点，如中文屋论证、符号主义与联结主义的对比。此外，用户可能希望了解当前AI发展的局限以及未来方向。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>接下来，我需要整理材料中的关键点。首先，书中探讨的核心问题是计算机能否成为心灵本身，而不仅仅是工具。这涉及到对强AI与弱AI的讨论，尤其是塞尔的中文屋论证。然后，书中分四个问题展开：计算机实现的智能类型、符号主义的局限性、联结主义的进展与问题，以及现实与理想AI的差距。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>在分析时，要注意区分符号主义和联结主义的不同哲学基础，前者根植于理性主义，后者受休谟经验主义影响。同时，书中提到的涉身认知和僵尸论证也是重要概念，需要解释清楚。此外，用户提供的总结要点需要准确反映原文内容，比如指出符号主义在处理复杂组合时的计算瓶颈，联结主义对数据的依赖，以及通用AI面临的挑战如情感体验和自我意识。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>可能需要注意的潜在问题包括术语的准确性，比如“中文屋论证”是否正确应用，符号主义与联结主义的定义是否清晰。另外，用户可能希望了解这些哲学讨论对当前AI技术的影响，比如AlphaGo的成功是否属于联结主义的应用，以及未来研究方向如涉身认知的实际应用。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>最后，确保回答结构清晰，逻辑连贯，涵盖用户提供的所有重点，并适当补充背景知识以帮助理解。需要确认是否遗漏了书中的任何关键论点，比如德雷福斯对AI的批判，或者图灵测试的相关讨论。同时，保持回答的专业性，但语言要通俗易懂，适合不同知识背景的读者。</span></span></code></pre></div><p>《人工智能哲学》一书通过15篇经典论文，系统梳理了人工智能领域核心哲学问题的演变。以下从四个维度对书中核心思想进行结构化总结：</p><p><strong>一、人工智能的本质之争</strong></p><ul><li><strong>中文屋悖论</strong>：塞尔通过&quot;中文屋&quot;思想实验，揭示符号操作与真实理解的本质差异，质疑强人工智能可能性。</li><li><strong>图灵测试回应</strong>：支持者认为系统整体行为符合智能标准即可视为智能，但塞尔指出这混淆了模拟与实现的本质区别。</li></ul><p><strong>二、技术路径的哲学溯源</strong></p><table tabindex="0"><thead><tr><th>流派</th><th>哲学基础</th><th>核心主张</th><th>典型应用</th><th>局限性</th></tr></thead><tbody><tr><td><strong>符号主义</strong></td><td>笛卡尔理性主义</td><td>智能即符号逻辑运算</td><td>专家系统</td><td>组合爆炸问题</td></tr><tr><td><strong>联结主义</strong></td><td>休谟经验主义</td><td>通过神经网络模拟学习过程</td><td>AlphaGo</td><td>数据依赖/创造性缺失</td></tr><tr><td><strong>具身认知</strong></td><td>现象学传统</td><td>智能需身体与环境互动</td><td>机器人学</td><td>技术实现难度大</td></tr></tbody></table><p><strong>三、现实与理想的鸿沟</strong></p><ol><li><strong>专用性局限</strong>：当前AI仅在封闭领域（如围棋）超越人类，缺乏通用认知架构</li><li><strong>情感黑箱</strong>：僵尸论证揭示机器可模拟情感反应，但无法产生主观体验</li><li><strong>自我意识缺失</strong>：现有系统缺乏&quot;我&quot;的概念，无法形成主体性认知</li><li><strong>具身性挑战</strong>：智能需身体作为认知媒介，纯算法难以复现具身智能</li></ol><p><strong>四、启示与前瞻</strong></p><ul><li><strong>哲学驱动创新</strong>：从符号主义到联结主义的范式转换，本质是哲学认知的革命</li><li><strong>技术伦理维度</strong>：情感计算引发&quot;人工意识&quot;伦理争议，需建立新伦理框架</li><li><strong>跨学科融合</strong>：认知科学、神经科学与工程学的深度协同将成为突破关键</li><li><strong>认知镜像效应</strong>：AI发展反向推动人类对意识本质的理解，形成认知革命闭环</li></ul><p>当前AI已实现特定领域的&quot;狭隘智能&quot;，但要突破通用人工智能的奇点，仍需解决意识主体性、具身认知建模、创造性推理等根本问题。正如德雷福斯所言，真正的突破可能来自对&quot;在世存在&quot;（Being-in-the-world）的机器实现，这需要哲学与技术的双重突破。</p><h2 id="修复文案" tabindex="-1">修复文案 <a class="header-anchor" href="#修复文案" aria-label="Permalink to &quot;修复文案&quot;">​</a></h2><p>关于作者</p><p>玛格丽特·A.博登，生于1936年，英国科学院院士，苏塞克斯大学认知科学学院院长，历任英国心理学会心理学哲学与心理学史分会主席，以及英国皇家哲学学会理事。著有《人工智能史》一书，是人工智能领域的权威人士。</p><p>关于本书</p><p>《人工智能哲学》的英文原著由牛津大学出版社于1990年出版，由15篇文章组成，文章作者多是人工智能思想界的著名人物，所收录的文章也都是在人工智能发展史上具有里程碑式的地位。这些文章的写作时间起于1950年，止于1990年，是人工智能思想近半个世纪发展历程的精要总结。</p><p>核心内容</p><p>计算机究竟能否成为心灵本身而不只是心灵的工具，既取决于我们如何理解计算机能做什么，更取决于我们如何理解人类心灵是什么。我们怎样认识自己的心灵，也就决定了我们会怎样设计机器，让它具备人工的智能。这既是人工智能构想的发端，也是影响着人工智能科学与技术进展的哲学基础。</p><p><img src="https://piccdn3.umiwi.com/img/201802/02/201802021821342604772910.jpg" alt=""></p><p>你好，欢迎每天听本书。本期为你解读的是一本人工智能领域的经典论文集，名字叫做《人工智能哲学》。这本书的中文版大约42万字，我会用大约23分钟的时间为你讲述书中精髓：计算机究竟能否成为心灵本身，而不只是心灵的工具？要回答这个问题，既取决于我们如何理解计算机能做什么，更取决于我们如何理解人类心灵是什么。这就是这本论文集的试图解答的问题。</p><p>我们先来看一个思想实验。</p><p>假设一个外国人被锁在一间屋子里，不断地收到从屋外递进来的中文纸条，但他只懂英语不懂中文，不能看懂纸条上的中文内容。再假设这个外国人收到的纸条上不仅有中文符号，还有一套用英文写的规则，告诉他如何找到对应的中文符号。最后他收到英文的指令，要求送回某些特定的中文符号。他就完全照着指令做了，找到了相应的中文符号，并且照葫芦画瓢地在纸条上写出来，再递出屋外。这个过程不断重复，那么在屋外的人看来，递进去的所有中文问题都得到了有效的回答。但我们会认为这个外国人确实懂中文了吗？显然不会，他只是按照英文的指令处理中文符号而已。</p><p>这就是在人工智能发展史上非常著名的“中文屋”论证。它的提出者是美国哲学家约翰•塞尔。中文屋论证的目的是反对“强人工智能”的理念。所谓的“强”当然是与“弱”相对的。在弱人工智能的意义上，计算机只是我们研究心灵的工具，比如它能验证许多关于心灵的假设。但是强人工智能的观点就不同了，它会认为计算机并不只是工具而已，而是有可能成为一个真正的心灵，能够像人类一样理解和认识这个世界。</p><p>但塞尔想说，计算机也不过就是中文屋里的人，尽管它能处理中文的符号、回答中文的问题，但这绝不是说计算机就“理解”了中文。实际上，计算机只是按照规则做运算，输出运算得出的结果，而并不能理解问题与答案的意义。所以，如果中文屋论证是成立的，那么强人工智能只不过是一种美妙的遐想，计算机充其量只能是人类心灵的工具，而不会成为心灵本身。</p><p>中文屋论证引起了广泛而热烈的讨论。实际上，围绕人工智能话题展开的类似讨论还有很多。玛格丽特•博登教授是英国科学院院士、苏塞克斯大学认知科学学院院长，她从这些讨论中挑选出有代表性的文章，编了这本取名《人工智能哲学》的论文集。</p><p>从这本书中，我们既能读到人工智能的先驱阿兰•图灵的教导，也能聆听像塞尔这样的当代哲学家的声音，还有当前的最新进展，比如机器学习理论的关键文章。可以说，这本书中选取的15篇经典论文，精要地总结了从上世纪五十年代开始，到上世纪末为止的人工智能哲学思想的发展，哪怕是最外行的读者也可以由此对人工智能的哲学基础有个基本的认识。</p><p>好了，下面我就为你详细讲述这本书的核心内容。计算机究竟能否成为心灵本身而不只是心灵的工具？机器能做到哪些事情会被看作是有了人类的智能？而要回答这些问题，我们首先需要弄清楚一个更基本的哲学问题，那就是：人类的心灵究竟是什么？可以说，从苏格拉底的时代以来，哲学家就一直在探讨这个事情。我们怎样认识自己的心灵，也就决定了我们会怎样设计机器，让它具备人工的智能。这既是人工智能构想的发端，也影响着人工智能科学与技术进展的哲学基础。</p><p>为讨论的简便，我先把它切分为四个更具体的问题。对这些问题的回答也正是书中内容的重点。第一个问题，计算机所能实现的人类智能究竟是什么？第二个问题，人工智能就是使用符号的计算吗？它有哪些缺点？第三个问题，人工智能就是模拟神经网络的学习吗？这又有什么不足？第四个问题，我们离实现完全的人工智能究竟还有多远？</p><p>好，咱们先来看第一个问题，计算机所能实现的人类智能究竟是什么？</p><p>人们或许都有一种朴素的直觉，认为有智能的心灵和身体不是一回事儿。身体更像是一架设计精良的机器，骨骼与肌肉的搭配，各个系统的协调，都要遵从一定的生理定律。心灵则不然，它似乎无边无际，不占有具体的空间，既可以感知客观，又能够恣意地想象乃至做白日梦。不仅普通人，哲学家也是这样想的。比如笛卡尔就认为，心灵与身体互不隶属，相互独立，是两类完全不同的东西。</p><p>然而，现代科学早已证明，心智不过是人类大脑实现的功能，如果大脑损伤了，通常也会产生心智方面的问题。如果真是这样，智能不过是身体实现的功能，那么同样的功能或许也能用其他机器来实现。这就是“人工智能”研究的基础前提。</p><p>据说在19世纪，英国剑桥大学有一个数学教授叫巴比奇，他就设计了一台分析机，完全用齿轮等机械部件来实现计算，至于电子计算机就更是多种多样了，什么电子管、晶体管、集成电路，一直到未来可能的量子计算机，机器的形式各不相同，但所实现的功能是类似的，都是试图模拟、实现人类的智能。</p><p>人类的智能体现在很多方面，计算和推理可能最容易在机器上实现。心灵的智慧可以从推理上体现出来。比如，你听到有人说“外面下雨了”，自然地推论出“出门要带伞”。这就是一个有效的推理，把它编码为符号规则，就能够在计算机上实现。</p><p>在这个推理中，人类的心灵能够理解“雨”和“伞”的概念以及两者之间的内在联系；但在机器的推理中，机器所处理的不过是一连串符号，这些符号对机器来说毫无意义，但机器在最后输出的答案却刚好被翻译成了我们能理解的内容。</p><p>所以，机器上实现的计算与推理，与人类的推理活动虽然有相似之处，但机器并不能“理解”计算的意义，这就很类似于中文屋的说法了。虽然计算机能够高效地回答问题，但它自己并没有理解。人类则不同，所有推理判断都必须建立在理解的基础上。对于完全不理解的问题，我们当然也不可能作出任何推理或回答。</p><p>然而，很多人工智能专家说，不能简单地用人类理解的标准来要求机器，计算机的“理解”有另外一套标准。</p><p>计算机科学之父和人工智能之父图灵有个很响亮的论断，他认为：“只要机器作出的回答与人类的回答不可分辨，机器实际上就已经在理解了。”很多人就说，按照图灵的这种观点，中文屋作为一个系统，的确是理解中文的。尽管中文屋里的人并不懂中文，但只要这整个系统所提供的答案与人类的回答没什么区别，那么这就已经具备智能，这就是说系统已经具有理解能力了。进一步推演的话，我们也可以说，计算机确实可以实现人类的智能，只不过这种智能暂时还局限在计算和推理层面上。</p><p>好了，上面讲的就是第一个问题，我们知道了：计算机至少能在计算和推理的层面上实现与人类相似的智能。接下来我们再来看第二个问题：人工智能就是使用符号的计算吗？它有哪些缺点？</p><p>我们前面已经说了，计算与推理是机器上最容易实现的人类智能。而这类智能最鲜明的特征就是使用符号。数字是最普通的计算符号。比如，你想想如何教小孩子做算术？实际上就是要教会他使用数字“3”这个符号。你要举很多例子说，“3”既可以代表三只苹果、三个香蕉，也可以是三个人，等等。一旦小孩子理解了数字“3”可以代表任何三个东西，他就只需要数字符号就能做运算了，而不需要每次都想到三个苹果、香蕉或三个人。</p><p>推理也是这样。我们前面说，从“外面下雨”推理出“出门要带伞”，这就是利用了“下雨”和“带伞”之间的符号关系。计算机或许没有“雨伞”的概念，但它完全可以有代表“雨”和“伞”的符号。利用这些符号，计算机就可以作推理，而它所得到的结论也可以完全符合人类推理的结果。</p><p>在人工智能发展的早期，人们相信，只要恰当地设计程序算法，使用符号的计算就能实现完全的智能。在这种信念的背后，其实是西方哲学两千多年的理性主义传统，相信理性能力就足以解释人类的所有智慧。这在人工智能的发展史上被称作符号主义观点，这本论文集作者中的纽厄尔和西蒙就是符号主义的支持者。</p><p>在符号主义者看来，人类的智能不管多么复杂，归根到底都是由符号计算来实现的。不管是爱因斯坦构思相对论，还是罗纳尔多创造精彩射门，甚至任何看起来不起眼的手工技艺，比如剪纸、捏泥人、书法篆刻等等，它们所体现的人类智能，说到底都是一些复杂的计算。所以，只要计算机科学家设计了适合的程序，计算机早晚有一天能够凭着符号的计算，也能提出相对论、创造罗纳尔多的射门，而剪纸捏泥人和书法篆刻就更不在话下了。</p><p>你可以想一想机器下象棋的例子。显然机器并不是人类，不能直接理解“马走日、象走田”这样的概念，但它能执行包含“0”和“1”的机器语言，所以，要让它会下棋，首先就要把象棋规则转换为只包含“0”和“1”的程序。尽管象棋的走法千变万化，最终都不过是这些最基本的符号叠加。而在一盘象棋游戏中，计算机的每一步究竟应该如何走，这就要在可能的选项中搜索最佳的方案。每一步可能的选项也是符号的组合，符号的任何组合方式都可能是一种选项，要考虑所有可能的选项，这个集合是非常庞大的。</p><p>因此，符号主义面临的最大挑战就是，如何在有限的步骤和资源的条件下，搜索得到最优的解。随着求解的问题越来越复杂，搜索所需要的计算也是以指数的方式在增长，因为符号之间的可能组合也在激增，这样一来，现实中工作的计算机很快就不堪重负了。</p><p>比如，计算机在中国象棋上相对容易表现出智能，但在国际象棋上就费了一些工夫，当年“深蓝”战胜国际象棋大师卡斯帕罗夫还成为轰动一时的新闻。而围棋的人工智能程序曾经在很长时间内表现得一点也不智能，就是因为围棋求解的组合要比象棋复杂得多，这正是符号主义难以解决的问题。</p><p>今天的人工智能引起如此大的轰动和关注，可以说是源于AlphaGo在围棋上取得了突破。解决围棋游戏最优解的问题超出了符号主义的能力，但AlphaGo恰恰不属于符号主义。在对它的报道中，我们常常听到这样一个词：“基于神经元网络的机器学习”，这就是区别于符号主义的另一种人工智能研究理念，也是我们今天要说的第三个问题：人工智能就是模拟神经网络的学习吗？这又有什么不足？</p><p>我们说过，符号主义来自于西方哲学中的理性主义传统，但这一传统在18世纪遭到了一位思想巨匠的深刻批评，他就是英国哲学家大卫•休谟。休谟认为，体现人类智能的很多判断，比如对因果关系的判断，尽管表面上看起来是依据理性和推理，实际上仅仅是源于我们在观念之间作联结的习惯。这种联结往往是在重复经验中实现的。比如，教一个小孩子要远离火，并不需要什么计算或推理，只需要让他重复经验到手靠近火苗会有灼烧感，他就会反射性地缩回去，那么下次他再见到火苗的时候就知道要小心躲避了。</p><p>休谟的这种观点后来在神经科学中得到了证实。科学家发现，神经元之间通过突触联结，当两个神经元同时得到频繁的刺激，两者之间的突触就越牢固，联结的强度也就增高，这其实就是人类的学习过程。我们读书的时候都有类似的经验：比如背诵英语单词，就需要刻意多重复几遍，记得就牢靠一些，就是因为需要强化在不同神经元之间建立的联结。</p><p>既然人类的智能在大脑中实际上就是这样来实现的，那么为什么人工智能不能以相同的模型来实现呢？这种区别于理性主义传统，而主要受休谟和神经科学思想启发的人工智能研究理念，就是“联结主义”。</p><p>与符号主义不同，联结主义认为，人工智能的首要任务是建立大脑的模型，不是预先给定解决问题的算法，而是构建一个在计算机上模拟的“神经元网络”，让机器自主地建立不同神经元之间的“联结”，通过最终结果的反馈，不断调整联结的模式，最终逼近最优解。在整个过程中，机器就像人类那样，在大量的经验数据中学习。由于机器处理数据的能力远超人类，所以学习效果也会大大超越人类。</p><p>设想一下，你家的冰箱不工作了，你需要找出原因出在哪儿，该怎么办？显然，首先需要考虑有哪些因素能造成影响，比如是冰箱坏了，还是电路老化短路了，还是插座不通电了，等等，然后就需要根据假设挨个检验，通过反馈的结果不断排除虚假的因素，最终找到真正的原因。</p><p>机器学习也是这样的试错法，当然可能面临的任务极为复杂，比如下围棋，那么所考虑的因素也极其丰富，超过人类大脑所能同时处理的能力；而且计算机上实现的神经网络还是分层的：不同层次上的神经元联结被分配到不同的权重，通过最终输出的结果与最优结果之间作比较，反馈回来再调整联结的方式与权重。AlphaGo正是在这种成百万上千万次的反复试错、调整中，学会了如何在围棋游戏的每一步都找到最优解，从而能够击败人类的围棋冠军。</p><p>显而易见，联结主义特别强调从经验学习中获得智能，所以就避开了符号主义过度强调理性推理的弊端，从而让人工智能获得了突破性的进展，但这也带来了新的问题：它实在太过执着于经验了，而且它并不会区别地对待经验。人类固然是从经验中学习，但人类的智能就体现在我们从不毫无差别地对待一切经验，而总是选择性地重视某些经验，忽略一些无关紧要的经验。联结主义的人工智能则要在海量数据的试错学习之后，才能获得某些在人类看来十分简单的结论，这种笨笨的表现看起来可不太智能。更重要的是，人类的学习是有创造性的，我们不仅能从经验中把握固有的联系，还能举一反三地创造以前从未建立过的神经元联结。如果不能实现这一点，机器学习就只能依赖于设计者提供给它的智能，而并不是自己产生的智能。</p><p>好，上面就是本书的第三个重点：总的说来，联结主义的人工智能取得了重要的进步，但过于依赖经验数据也是它所面临的新问题。那我们离理想的人工智能究竟还有多远呢？这就是我们要说的最后一个问题了。</p><p>不用多说，你肯定也能感觉到目前人工智能所达到的水平，与那些科幻小说与电影里描绘的人工智能，还有不小的距离。首先，现在实现的都只是专门的人工智能，而不是通用性的智能。在科幻作品里，完全实现人工智能意味着人类心灵的再造与替换，几乎就是一个完整的个人，能够做人类心灵的所有任务，而不局限于某一类专门任务。</p><p>而今天我们实现的人工智能基本都不是通用的。比如AlphaGo，它就是被设计来下围棋的。虽然它在下围棋方面表现得比人类的围棋冠军还要好，但它并不具备人类心灵的其他功能，比如说它并不能既会下围棋，又会炒菜，还会谈恋爱。我们每个人的心灵都是多面手，而现阶段的人工智能往往只能在某一个侧面充分发展。</p><p>其次，人工智能还可能永远无法理解人类的情感。理想的人工智能应该具备人的感受、体悟、情绪与痛苦，是人类能够从情感上交流与接纳的对象。但在目前联结主义的方案中，训练机器“理解”情感和动机，主要就是着眼于让机器学习如何产生行为的目标。</p><p>人类的情感的确能产生行为目标，假如你非常爱慕某个女孩，你就会产生“把她追到手”的目标，但这显然不是人类情感最核心的部分。我们通常会说，如果你非常爱慕她，你就一定会体会到爱慕之情带来的那种幸福、甜蜜、纠结又失落的感受。没有这些感受的体验，或者对这些感受麻木不仁，你就不叫真正爱过一个人，也就无法理解情感为何物。</p><p>换句话说，情感最本质的内涵应该是对情绪的主观感受，而这恰好是人工智能难以实现的。可以设想，我们所造出的人工智能机器，哪怕能够实现所有情感功能，也仍然缺乏情感的主观感受。这就是当代哲学中非常有名的“僵尸论证”。我们这里所说的僵尸，并不是大家在僵尸电影里看到的那些行尸走肉，而是说，任何人都可以设想自己有一个这样的复制品，它不论从外观上还是说话做事、行为举止上，都和自己一模一样，但唯一有一点不同，就是僵尸没有你的主观感受。它也可以说“红色”，但并没有我们看到红色的那种感受；可以说“疼痛”，但从没有痛感；更可以说爱与恨，但同样不知道爱恨情仇为何物。总之，这个像僵尸一样的复制品虽然能够模仿人类的情感功能，但是缺乏人们对情感的主观感受。</p><p>而最根本的困难可能还在于，对人工智能来说，根本还没有一个“自己”。它没有形成自我意识，没有把自己看作一个“我”，从而也就不可能有主观的视角。那么，机器是否能具有自我意识？科幻作品中那些完美的人工智能都是有的，而要真正实现这一点，还需要很多科学与哲学上的探索。</p><p>赫伯特•德雷福斯就是对人工智能的发展产生过重要影响的当代哲学家。他认为，人工智能要想真正实现，就不能仅仅把智能当作是发生在人类大脑中的事情，而必须认真思考身体对智能的意义。实际上，自笛卡尔以来，西方哲学一直就有一项根深蒂固的偏见，人们总是把自我等同于心灵，而没有看到，人们对自我与世界的认识，从来都是有身体参与其中的。</p><p>比如，网球运动员面对快速飞来的网球，没有犹豫更没有时间思考，他的手臂就像自然反应一样发力挥动球拍，球就被准确击中并改变飞行的方向。在更多的时候，人们就像这个网球运动员一样，运用身体的自然倾向自如地与世界打交道，完全不必“三思而后行”。虽然这些行为看起来并不复杂，也无需思维活动的参与，但没有人会因此怀疑这不是智能，而恰恰是熟练发挥人类智能的体现。</p><p>这种包含着身体在内的智能在今天的哲学中有一个专门的说法，叫做“涉身认知”。与此相比，过去的哲学家是过于强调认知的理性面了，不管是符号主义还是联结主义，都是把智能和认知看作人类心灵的产物，根本不考虑身体的状态。但是，假如智能和认知本质上就涉及身体，假如涉身认知的观念是正确的，那么符号主义与联结主义就都有各自的局限，人工智能的发展，势必还需要由新的观念来引领。</p><p>总之，从专门化与通用性的区别、情绪的主观感受、自我意识和涉身认知等几方面来看，今天的人工智能离理想的人工智能水平还相距甚远。但这并不代表未来就没有实现的可能。纵观历史，人工智能的进步依赖于提出创新性的思想与方法。符号主义的提出、联结主义对符号主义的超越，以及涉身认知的新方向，都是例证。可以预见，未来还会有人提出更具创造性的人工智能思想，让机器拥有心灵的梦想逐步成为现实。</p><p>好了，说到这里，《人工智能哲学》这本书的主要内容就讲完了，我们再来回顾一下今天谈的四个核心问题：</p><p>首先，我们谈了计算机所能实现的人类智能，其实就是计算和推理的智能。</p><p>然后我们说到了引领人工智能发展的符号主义，它来自于西方哲学中的理性主义传统，但很难非常复杂的求解组合中快速找到最优解。</p><p>比符号主义更进一步的人工智能理念是联结主义，它通过神经元网络的机器学习来实现智能，但又过于依赖经验数据，这并不像人类智能的样子。</p><p>最后，我们说到了现实与理想的人工智能之间的距离。这个距离仍然不小，理想的人工智能应当是通用的而非专门化的智能，是能够具有情感的主观感受、自我意识和涉身认知的智能，但这些功能目前都还难以实现，我们期待着人工智能新思想的提出与突破。</p><p>回到塞尔的中文屋，在了解了这么多话题之后，你觉得人工智能的发展能回应这个思想实验的挑战吗？单纯使用符号的计算或许还不是“理解”，那么在大数据的学习中建立的神经元联结呢？似乎就更像人类的理解，因为我们去理解某个现象，无非就是建立一种稳定的联结模式。未来还可能实现的人工智能，也许会是一个通用的、具备情绪感受、自我意识和涉身认知的智能主体，它能够处理人类心灵所有擅长的各种任务，而不仅仅是像中文屋那样的翻译机器。</p><p>但中文屋的思想实验对我们来说还是很重要的。人工智能固然是要制造人工的心灵，但完全实现制造心灵的目标，并不是这项事业的终极价值。更重要的是，人工智能的实现进一步加深了我们对自身的理解，促使我们不断追问到底什么是智能、什么是理解。中文屋就是这样一个反思的契机，这也是塞尔对人工智能哲学做出的最独特的贡献。</p><p>撰稿：徐竹 脑图：摩西 转述：孙潇</p><p>1.人类智能，其实就是计算和推理的智能。 2.符号主义认为，人类的智能不管多么复杂，归根到底都是由符号计算来实现的;联结主义通过神经元网络的机器学习来实现智能，但又过于依赖经验数据，这并不像人类智能的样子。 3.理想的人工智能应当是通用的而非专门化的智能，是能够具有情感的主观感受。要想真正实现，就不能仅仅把智能当作是发生在人类大脑中的事情，而必须认真思考身体对智能的意义。</p>`,74))])}const _=o(d,[["render",m]]);export{u as __pageData,_ as default};
