import{f as A,D as o,c as B,o as i,a1 as r,b as e,k as s,w as E,a as l,H as p,a2 as t}from"./chunks/framework.Baju3tsf.js";const q=JSON.parse('{"title":"《玻璃笼子》| 张凯解读","description":"自动化为什么让我们的技能退化？我们做出的决策，是自己的判断还是程序的诱导？自动化如何干扰我们隐性知识的获得？面对自动化大趋势，我们如何保持清醒？","frontmatter":{"title":"《玻璃笼子》| 张凯解读","description":"自动化为什么让我们的技能退化？我们做出的决策，是自己的判断还是程序的诱导？自动化如何干扰我们隐性知识的获得？面对自动化大趋势，我们如何保持清醒？","created":"2025-01-18T16:07:09.000Z","modification_date":"2025-01-18T16:07:09.000Z","tags":["书籍解读/科技批判"],"cover_url":"https://piccdn3.umiwi.com/img/201803/09/201803091635091519318179.jpg?x-oss-process=image/resize,m_fill,h_224,w_168","source":"https://www.dedao.cn/audioBook/detail?id=Xpv4BMYRxDeLWaJR9rV6aZokG8mwK9&score=4.7&learn_count=10万次学习","author":null},"headers":[],"relativePath":"categories/dedao/《玻璃笼子》张凯解读.md","filePath":"categories/dedao/《玻璃笼子》张凯解读.md"}'),d={name:"categories/dedao/《玻璃笼子》张凯解读.md"};function u(h,a,g,c,m,D){const n=o("Mermaid");return i(),B("div",null,[a[3]||(a[3]=r('<h1 id="《玻璃笼子》张凯解读" tabindex="-1">《玻璃笼子》张凯解读 <a class="header-anchor" href="#《玻璃笼子》张凯解读" aria-label="Permalink to &quot;《玻璃笼子》张凯解读&quot;">​</a></h1><h2 id="可视化总结" tabindex="-1">可视化总结 <a class="header-anchor" href="#可视化总结" aria-label="Permalink to &quot;可视化总结&quot;">​</a></h2><p>#书籍解读/科技批判</p><h2 id="mermaid-流程图" tabindex="-1">Mermaid 流程图 <a class="header-anchor" href="#mermaid-流程图" aria-label="Permalink to &quot;Mermaid 流程图&quot;">​</a></h2>',4)),(i(),e(t,null,{default:E(()=>[p(n,{id:"mermaid-12",class:"mermaid",graph:"graph%20LR%0AA%5B%E7%94%A8%E6%88%B7%E4%BD%BF%E7%94%A8%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7%5D%20--%3E%20B%7B%E5%B7%A5%E5%85%B7%E6%8F%90%E4%BE%9B%E4%BE%BF%E5%88%A9%7D%3B%0AB%20--%20%E9%95%BF%E6%9C%9F%E4%BD%BF%E7%94%A8%20--%3E%20C%5B%E6%8A%80%E8%83%BD%E9%80%80%E5%8C%96%5D%3B%0AC%20--%3E%20D%5B%E4%BE%9D%E8%B5%96%E8%87%AA%E5%8A%A8%E5%8C%96%5D%3B%0AD%20--%3E%20E%7B%E5%86%B3%E7%AD%96%E8%83%BD%E5%8A%9B%E4%B8%8B%E9%99%8D%7D%3B%0AE%20--%3E%20F%5B%E6%80%9D%E7%BB%B4%E9%92%9D%E5%8C%96%5D%3B%0AF%20--%3E%20G((%E6%81%B6%E6%80%A7%E5%BE%AA%E7%8E%AF))%3B%0A"})]),fallback:E(()=>a[0]||(a[0]=[l(" Loading... ")])),_:1})),a[4]||(a[4]=s("h2",{id:"mermaid-状态图",tabindex:"-1"},[l("Mermaid 状态图 "),s("a",{class:"header-anchor",href:"#mermaid-状态图","aria-label":'Permalink to "Mermaid 状态图"'},"​")],-1)),(i(),e(t,null,{default:E(()=>[p(n,{id:"mermaid-16",class:"mermaid",graph:"stateDiagram%0A%20%20%20%20%5B*%5D%20--%3E%20%E6%89%8B%E5%8A%A8%E6%93%8D%E4%BD%9C%3A%20%E4%BA%BA%E5%B7%A5%E4%B8%BB%E5%AF%BC%0A%20%20%20%20%E6%89%8B%E5%8A%A8%E6%93%8D%E4%BD%9C%20--%3E%20%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BE%85%E5%8A%A9%3A%20%E5%BC%95%E5%85%A5%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7%0A%20%20%20%20%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BE%85%E5%8A%A9%20--%3E%20%E8%BF%87%E5%BA%A6%E4%BE%9D%E8%B5%96%3A%20%E4%BE%9D%E8%B5%96%E8%87%AA%E5%8A%A8%E5%8C%96%E5%86%B3%E7%AD%96%0A%20%20%20%20%E8%BF%87%E5%BA%A6%E4%BE%9D%E8%B5%96%20--%3E%20%E6%8A%80%E8%83%BD%E9%80%80%E5%8C%96%3A%20%E5%A4%B1%E5%8E%BB%E5%85%B3%E9%94%AE%E6%8A%80%E8%83%BD%0A%20%20%20%20%E6%8A%80%E8%83%BD%E9%80%80%E5%8C%96%20--%3E%20%E9%A3%8E%E9%99%A9%E5%A2%9E%E5%8A%A0%3A%20%E9%9D%A2%E5%AF%B9%E7%AA%81%E5%8F%91%E7%8A%B6%E5%86%B5%E8%83%BD%E5%8A%9B%E4%B8%8D%E8%B6%B3%0A%20%20%20%20%E9%A3%8E%E9%99%A9%E5%A2%9E%E5%8A%A0%20--%3E%20%5B*%5D%0A"})]),fallback:E(()=>a[1]||(a[1]=[l(" Loading... ")])),_:1})),a[5]||(a[5]=s("h2",{id:"mermaid-思维导图",tabindex:"-1"},[l("Mermaid 思维导图 "),s("a",{class:"header-anchor",href:"#mermaid-思维导图","aria-label":'Permalink to "Mermaid 思维导图"'},"​")],-1)),(i(),e(t,null,{default:E(()=>[p(n,{id:"mermaid-20",class:"mermaid",graph:"mindmap%0A%20%20root((%E7%8E%BB%E7%92%83%E7%AC%BC%E5%AD%90%20-%20%E8%87%AA%E5%8A%A8%E5%8C%96%E7%9A%84%E9%9A%90%E6%82%A3))%0A%20%20%20%20%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%A6%E6%9D%A5%E7%9A%84%E9%97%AE%E9%A2%98%0A%20%20%20%20%20%20%E8%BF%87%E5%BA%A6%E4%BE%9D%E8%B5%96%0A%20%20%20%20%20%20%20%20%E8%A2%AB%E5%B7%A5%E5%85%B7%E5%AE%A0%E5%9D%8F%0A%20%20%20%20%20%20%20%20%E5%A4%B1%E5%8E%BB%E5%86%B3%E7%AD%96%E8%83%BD%E5%8A%9B%0A%20%20%20%20%20%20%20%20%E6%80%9D%E7%BB%B4%E9%92%9D%E5%8C%96%0A%20%20%20%20%20%20%E9%81%93%E5%BE%B7%E5%9B%B0%E5%A2%83%0A%20%20%20%20%20%20%20%20%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E7%9A%84%E4%BC%A6%E7%90%86%E9%80%89%E6%8B%A9%0A%20%20%20%20%20%20%20%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E9%81%93%E5%BE%B7%E7%BA%A6%E6%9D%9F%20%20%0A%20%20%20%20%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%0A%20%20%20%20%20%20%E4%BF%9D%E6%8C%81%E6%B8%85%E9%86%92%0A%20%20%20%20%20%20%20%20%E5%9D%9A%E6%8C%81%E5%B7%A5%E4%BD%9C%0A%20%20%20%20%20%20%20%20%E4%BA%BA%E6%9C%BA%E7%BB%93%E5%90%88%0A%20%20%20%20%20%20%E6%89%BE%E5%88%B0%E8%87%AA%E8%BA%AB%E4%BB%B7%E5%80%BC%0A%20%20%20%20%20%20%20%20%E4%B8%8D%E5%8F%AF%E6%9B%BF%E4%BB%A3%E7%9A%84%E6%8A%80%E8%83%BD%0A%20%20%20%20%20%20%20%20%E5%88%9B%E9%80%A0%E5%8A%9B%E4%B8%8E%E6%80%9D%E8%80%83%E5%8A%9B%0A%20%20%20%20%E4%BD%9C%E8%80%85%E8%A7%82%E7%82%B9%0A%20%20%20%20%20%20%20%20%E7%A7%91%E6%8A%80%E5%8F%91%E5%B1%95%E5%88%A9%E5%BC%8A%E5%85%B1%E5%AD%98%0A%20%20%20%20%20%20%20%20%E8%AD%A6%E6%83%95%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%A6%E6%9D%A5%E7%9A%84%E8%B4%9F%E9%9D%A2%E5%BD%B1%E5%93%8D%0A%20%20%20%20%20%20%20%20%E4%BF%9D%E6%8C%81%E7%8B%AC%E7%AB%8B%E6%80%9D%E8%80%83%E5%92%8C%E5%88%A4%E6%96%AD%E8%83%BD%E5%8A%9B%0A%0A%0A"})]),fallback:E(()=>a[2]||(a[2]=[l(" Loading... ")])),_:1})),a[6]||(a[6]=r(`<h2 id="内容总结" tabindex="-1">内容总结 <a class="header-anchor" href="#内容总结" aria-label="Permalink to &quot;内容总结&quot;">​</a></h2><div class="language-ad-think vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">ad-think</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>嗯，用户提供了一篇关于《玻璃笼子》这本书的详细讲稿，需要我生成一个总结。首先，我需要理解用户的需求。看起来他们可能希望得到一个结构化的书籍摘要，涵盖作者、核心内容以及主要观点。用户可能是想快速了解这本书的核心思想，或者用于分享、学习参考。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>接下来，我需要分析讲稿的结构。讲稿分为关于作者、关于本书、核心内容四个点，每个点都有详细说明，最后还有撰稿人信息。用户可能希望将这些信息浓缩成一个清晰的大纲，方便阅读。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>然后，我要确定如何组织这些信息。通常，书籍摘要包括作者简介、书籍主题、核心观点分点阐述，以及总结建议。用户提供的核心内容已经分成了四点，所以可以按照这个结构来整理。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>需要注意的是，用户可能希望保留具体例子，如飞行员技能退化、GPS对因纽特人的影响等，因为这些例子能增强说服力。同时，用户提到的解决方案部分，如工作悖论实验和波音与空客的例子，也需要在总结中体现，以展示如何应对自动化带来的问题。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>另外，用户可能希望强调作者的写作风格，即与主流观点唱反调，提醒读者科技的双刃剑效应。这点应该在摘要中突出，以体现本书的独特视角。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>最后，要确保语言简洁明了，避免冗长，使用户能快速抓住重点。可能需要使用分点、加粗标题等方式提高可读性。同时，注意不要遗漏重要信息，如自动化对道德的影响和未解决的问题，这也是本书的重要论点。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>检查是否有重复或冗余的内容，比如在核心内容中，每个点都有例子支撑，需要确保这些例子在摘要中得到恰当呈现。此外，用户提供的图片链接可能无法显示，但可以忽略，除非有特别说明。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>总结来说，我需要将讲稿转化为结构清晰、重点突出的摘要，涵盖作者、主题、四个核心观点及应对策略，保持语言简洁，使用例子增强论点，并突出作者的批判性视角。确保最终输出符合用户需求，便于理解和传播。</span></span></code></pre></div><h1 id="《玻璃笼子》深度解析-自动化时代的清醒之思" tabindex="-1">《玻璃笼子》深度解析：自动化时代的清醒之思 <a class="header-anchor" href="#《玻璃笼子》深度解析-自动化时代的清醒之思" aria-label="Permalink to &quot;《玻璃笼子》深度解析：自动化时代的清醒之思&quot;">​</a></h1><h2 id="作者背景" tabindex="-1"><strong>作者背景</strong> <a class="header-anchor" href="#作者背景" aria-label="Permalink to &quot;**作者背景**&quot;">​</a></h2><ul><li><strong>尼古拉斯·卡尔</strong>：哈佛大学毕业生，《哈佛商业评论》前执行主编，以批判性技术观察闻名</li><li><strong>代表作品</strong>：《浅薄》（揭示互联网对深度思考的侵蚀）《玻璃笼子》（探讨自动化陷阱）</li></ul><hr><h2 id="核心论点" tabindex="-1"><strong>核心论点</strong> <a class="header-anchor" href="#核心论点" aria-label="Permalink to &quot;**核心论点**&quot;">​</a></h2><h3 id="i-工具驯化-技能退化的隐形代价" tabindex="-1"><strong>Ⅰ 工具驯化：技能退化的隐形代价</strong> <a class="header-anchor" href="#i-工具驯化-技能退化的隐形代价" aria-label="Permalink to &quot;**Ⅰ 工具驯化：技能退化的隐形代价**&quot;">​</a></h3><ul><li><p><strong>案例1：飞行员危机</strong></p><ul><li>95%飞行员承认自动化导致手动飞行能力退化</li><li>2009年美大陆航空空难：自动驾驶失效时操作失误引发惨剧</li><li>现代飞行员日均手动操作仅3分钟，沦为&quot;按钮操作员&quot;</li></ul></li><li><p><strong>案例2：因纽特人导航危机</strong></p><ul><li>传统定位能力（观星/辨雪）因GPS普及濒临失传</li><li>GPS故障导致捕猎事故率上升，极地生存技能断层</li></ul></li><li><p><strong>神经科学佐证</strong></p><ul><li>纸质地图使用者海马体更活跃，电子导航加速认知退化</li><li>《科学》研究：真实场景与屏幕模拟的脑区激活差异显著</li></ul></li></ul><h3 id="ii-决策让渡-算法接管人类判断" tabindex="-1"><strong>Ⅱ 决策让渡：算法接管人类判断</strong> <a class="header-anchor" href="#ii-决策让渡-算法接管人类判断" aria-label="Permalink to &quot;**Ⅱ 决策让渡：算法接管人类判断**&quot;">​</a></h3><ul><li><p><strong>典型案例</strong></p><ul><li>1995年GPS故障撞船事件：船长盲目信任错误数据</li><li>电子病历系统推高医疗成本：算法建议过度检查</li><li>优衣库&quot;脑波选衣&quot;：消费决策被数据预测框定</li></ul></li><li><p><strong>决策权转移</strong></p><ul><li>传统工具（杠杆/车轮）增强人类能力</li><li>现代自动化（大数据+算法）直接接管决策流程</li></ul></li></ul><h3 id="iii-思维钝化-生成效应的消失" tabindex="-1"><strong>Ⅲ 思维钝化：生成效应的消失</strong> <a class="header-anchor" href="#iii-思维钝化-生成效应的消失" aria-label="Permalink to &quot;**Ⅲ 思维钝化：生成效应的消失**&quot;">​</a></h3><ul><li><p><strong>认知机制</strong></p><ul><li>生成效应：主动思考比被动接收记忆深刻度提升50%</li><li>多感官协同（眼/耳/手）构建深度知识网络</li></ul></li><li><p><strong>现实表现</strong></p><ul><li>心算能力普遍退化，数学思维培养受阻</li><li>电子笔记削弱知识内化，隐性知识流失加速</li></ul></li></ul><h3 id="iv-道德困境-自动化未解之题" tabindex="-1"><strong>Ⅳ 道德困境：自动化未解之题</strong> <a class="header-anchor" href="#iv-道德困境-自动化未解之题" aria-label="Permalink to &quot;**Ⅳ 道德困境：自动化未解之题**&quot;">​</a></h3><ul><li><p><strong>自动驾驶伦理困境</strong></p><ul><li>布鲁金斯学会经典命题：乘客安全vs路人伤亡的算法抉择</li><li>2018年Uber自动驾驶致死案引发责任归属争议</li></ul></li><li><p><strong>AI道德边界</strong></p><ul><li>恐怖主义场景：机器人是否执行反人类指令</li><li>医疗AI诊断失误的法律追责困境</li></ul></li></ul><hr><h2 id="破局之道" tabindex="-1"><strong>破局之道</strong> <a class="header-anchor" href="#破局之道" aria-label="Permalink to &quot;**破局之道**&quot;">​</a></h2><h3 id="双重防御策略" tabindex="-1"><strong>双重防御策略</strong> <a class="header-anchor" href="#双重防御策略" aria-label="Permalink to &quot;**双重防御策略**&quot;">​</a></h3><ol><li><p><strong>认知保持</strong></p><ul><li><strong>工作悖论实验</strong>：100人样本显示适度工作提升幸福感（成就感&gt;空虚感）</li><li>定期&quot;数字斋戒&quot;：恢复手动操作维持技能活性</li></ul></li><li><p><strong>人机协同设计</strong></p><ul><li>波音vs空客模式对比： <ul><li>空客：计算机拥有最终否决权</li><li>波音：驾驶员保留核心决策权</li></ul></li><li>医疗领域：AI辅助诊断+医生综合研判模式</li></ul></li></ol><hr><h2 id="启示录" tabindex="-1"><strong>启示录</strong> <a class="header-anchor" href="#启示录" aria-label="Permalink to &quot;**启示录**&quot;">​</a></h2><ul><li><strong>技术清醒剂</strong>：自动化≠进步，需警惕&quot;便利陷阱&quot;</li><li><strong>不可替代性</strong>： <ul><li>作家的意境创造</li><li>医生的经验直觉</li><li>设计师的原创思维</li></ul></li><li><strong>终极追问</strong>：当技术开始定义人类价值，我们是否正在沦为&quot;数字佃农&quot;？</li></ul><blockquote><p>&quot;真正的自由，在于掌控工具而非被工具掌控。&quot; —— 尼古拉斯·卡尔技术批判三部曲的核心警示</p></blockquote><h2 id="修复文案" tabindex="-1">修复文案 <a class="header-anchor" href="#修复文案" aria-label="Permalink to &quot;修复文案&quot;">​</a></h2><p><strong>关于作者</strong></p><p>尼古拉斯·卡尔，美国著名的作家、思想家、技术、创新和战略研究专家，毕业于哈佛大学，曾经担任《哈佛商业评论》执行主编。</p><p><strong>关于本书</strong></p><p>从主流观点的反面角度，提醒我们自动化给我们带来的危害，告诉我们如何在自动化的大趋势中保持清醒。</p><p><strong>核心内容</strong></p><p>第一点，我们在慢慢的被周围的工具宠坏；第二点，自动化替代了我们的决策能力；第三点，自动化会钝化我们的思维；第四点，自动化还有未解决的道德问题。</p><p><img src="https://piccdn3.umiwi.com/img/201612/19/201612191503022122808051.jpg" alt=""></p><p>欢迎每天听本书。今天说的这本书叫《玻璃笼子》，作者叫尼古拉斯·卡尔，他是美国著名的作家和思想家，也是技术、创新和战略研究专家，毕业于哈佛大学，曾经担任《哈佛商业评论》执行主编。</p><p>他除了这本书，还有一本很出名的畅销书，叫做《浅薄》，你可能听过，在那本书里他的一个主要观点就是，互联网让我们的思维方式变得越来越浅薄，我们不会再像以前那样深入地去思考问题了。不管你同不同意这个观点，他都提出了一个新颖角度，就是现代科技给我们带来的不仅仅是便利，随之而来的还有很多隐患。</p><p>这就是这位作者的写作风格，它总是和我们现在的主流观点唱反调，乍一听他的观点，好像一个进入垂暮之年的老人看现代什么新东西都不顺眼，什么都要抱怨几句，实际上仔细想想他说的也不无道理，任何事情都有两面性，我们在享受现代科技带来便利的同时，是不是也应该仔细审视一下它从我们身上偷走了哪些东西。</p><p>现在我们只要手里有手机、电脑，就可以搞定大部分的事情。但是大家也都有这种感觉，如果手机丢了，造成的麻烦也比以前大多了，以前丢了手机更多时候是心疼钱和有用的电话号码，现在手机丢了，起码得先冻结支付宝、微信、网银，然后再把密码重新修改，还得防止别人通过自己的账号去跟亲朋好友诈骗、盗刷自己的银行卡。可以说丢手机不是最可怕的，最可怕的是丢了手机之后的各种信息泄露和后续的麻烦。</p><p>你看，我们和手机的关系，其实是一个相互驯化的过程，就像我们的祖先种植小麦一样，表面上看是小麦给我们带来了食物，实际上我们也被小麦给驯养了，我们的祖先从游牧的生活状态变成了农耕的状态，身体也开始变得不适应野外生存，各种生存技能慢慢退化，这是一个相互驯化的过程。</p><p>手机也是一样，作者就认为，手机在给我们带来方便的同时，也把我们给圈在了一个玻璃笼子里。这个笼子看上去是透明的，不耽误我们看外面的世界，但其实我们是被死死地卡在里面，根本没办法出来。下面我们就来看看，作者所说的这个玻璃笼子是怎么样的。</p><p>第一点，作者认为，我们在慢慢地被周围的工具宠坏。</p><p>现在可以说很多事情都是自动化帮我们搞定的，扫地可以让机器人做、去陌生的地方可以用导航、自动驾驶的汽车也准备投入量产。由此带来的一个结果就是，我们的工作变得更加机械了，以前可能还需要写写画画的事情，现在就是敲敲键盘，把预先设计好的东西输入到固定的程序就可以了。</p><p>作者就说了飞行员技术退步的例子。咱们都知道，选飞行员是特别严格的，身高体重都有标准，不能有关节、骨骼、皮肤、器官上面的任何疾病，还得有健康的心理状态，然后经过严格的、长时间的训练之后，才有资格飞行。</p><p>在飞行时，飞行员需要保持高度的精神集中，准确操纵工具和设备，同时在大脑里面迅速做出计算、预测和评估，还得留意各种情况和信号。按道理来说，这么严格的筛选、这么高难度的工作，飞行员的技术应该是很厉害的，但是在2012年欧洲航空安全局对飞行员做出的调查报告显示，95%的飞行员表示自动化会影响他们的手动飞行能力和认知能力，让他们的技能慢慢退化了，有一位资深的机长就说，现在的飞行员已经不需要学习任何技术，只需要按按钮就可以了。</p><p>当然，咱们这里也不是说自动化技术是不好的，它对飞行安全其实有很多贡献，比如能帮助飞行员缓解疲劳，还能预警飞行风险，但是这也出现了一种新型的事故。在2009年，美国大陆航空公司一架客机就遇到了飞行事故。在起飞的时候是用手动驾驶，等飞稳以后，就转入到了自动驾驶模式，机长就开始和其他驾驶员聊天，就在快接近终点的时候，飞机的自动驾驶仪失灵了，机长就得开始重新驾驶，但是这时候由于它一连串的错误操作，让飞机彻底失控坠落。</p><p>事后，对事故的分析认为，主要的责任就在于飞行员团队缺乏应急反应能力和驾驶员的操作失误。这种事故就是在飞机失灵、需要飞行员马上做出反应的时候，由于之前太依赖自动飞行技术，导致飞行员的敏锐性和反应的准确度降低。每次飞行只需要3分钟的手动操作，其余的时间就盯着设备数据就可以了。这就让一个飞行员变成了一个电脑操作员。有一项针对警戒性的研究发现，让一个人盯着数据显示屏，保持专注的时间很难超过半小时。所以让我们一直监控着仪表盘，或者是自动化设备输出的数据，对我们的注意力本身就是一个挑战。这样就容易导致心理运动技能的退化，就是说飞行员会忘掉一些之前训练时候习得的知识，所以一旦有突发状况，就增大了发生事故的风险。</p><p>又比如说 GPS 也让我们的定位能力退化，最有代表性的就是因纽特人。我们都知道，因纽特人生活在北极，除了冰就是雪，做好的标记，可能一晚上就被冰雪覆盖没了。但是他们仍然有着超级厉害的定位能力，他们可以不用地图、指南针，就依靠星星、风向甚至是雪堆的形状就能判断定位。听起来特别逆天吧，这个就是他们在漫长的进化过程中，学会的特殊技能，但学习这个技能是需要跟着年长的老人学习，需要费很长时间才能完全学会的。</p><p>但是近些年来，GPS 的引入，让他们的这个技能慢慢地退化了，因为仪器用起来很方便，他们也不用花时间花精力去拜师学艺了，直接拿着设备跟着走就可以。但奇怪的是，随着 GPS 的使用率增加，捕猎事故的数量也增加了。因为猎人对定位特别依赖，又没有学会祖传的定位技术，在北极那种极端天气条件下，导航比较容易结冰、没电，一旦导航仪坏了，就会直接让猎人陷入绝境。还有人预言，照这样的节奏下去，可能再过两代人，因纽特人的这种定位能力就会彻底消失。</p><p>那我们来看看导航和纸质地图对我们的影响有什么不一样。有研究就表明，在一段旅行结束之后，用地图的旅行者能够更清晰地回忆起走过的线路，能更完整地回忆起整个地图。因为大脑的海马体里有定位细胞的，这些定位细胞会不断地强化我们的记忆能力，老年痴呆症最初的明显症状就是海马体和内嗅皮质退化。也就是说，如果一直不使用大脑的导航功能，海马体就会开始萎缩，这会大大加大我们患老年痴呆症的可能。</p><p>关于定位细胞，《科学》杂志也发表过一个研究，科学家发现大脑对真实的场景和屏幕中的模拟场景，定位细胞的反应是不一样的。他们找了兔子、老鼠这类动物，让它们分别体验两个相似场景，其中一个是真实的场景，一个是电脑中的场景，在真实世界的时候，这些细胞是很活跃的，但是在看电子屏的时候，虽然效果很逼真，但是它们的触觉、味觉、嗅觉、身体的活动并没有被激发，所以虽然看起来这两个场景是相似的，但大脑的活跃程度可有着很大的区别。当我们习惯了电子屏提供的材料，会认为这就是我们真正接触到的东西，这就会让我们的识别能力慢慢地退化。</p><p>第二点，作者认为，自动化替代了我们的决策能力。</p><p>最早我们发明工具，是为了节省体力、提高效率。比如抬东西太累了，我们就发明出来杠杆、滑轮。长途搬运东西、走路太累了，就发明了轮子和汽车，手工制作太慢了就发明了机器，虽然有了这些工具，但我们的关键决策权力还在自己手里。现在自动化可就不一样了，它背后有庞大的数据库和科学的算法，精确度比较高，有时候我们也会觉得，这些技术特别懂我们，于是我们就越来越相信程序做出来的判断，这样就容易在不知不觉中遵守自动化做出的决定。</p><p>比如作者给出了一个例子，1995年的时候，有一艘客轮，装了当时最先进的 GPS 系统，起航一个小时以后，这个设备的天线就松掉了，但是并没有完全断开，还能够继续提供数据。走着走着这艘船的船长就觉得不对劲，但是又说不出来哪里不对劲，如果是以前，他会停下来仔细测量一番再走，但是现在数据就摆在眼前，船长偷了一个懒，直接选择相信数据，最后导致这艘船撞上了礁石，造成了一起不必要的海难。这就是过度依赖自动化带来的后果，它会慢慢偷走我们最基本的决策能力。你肯定也听说过不少跟着导航直接开车掉沟里，或是跟着导航直接闯入了机场隔离区的新闻。生活中这样的事情时刻都在发生，导航是个重要工具，但它无终究无法代替我们的判断。</p><p>再比如说，现在的医院大部分都是电子病历系统。医生把你的症状、开的什么药、做过的什么检查都记录下来。这样能够很快调出来病人之前的情况，但是美国的医院在用过一段电子病历之后，就发现病人的医药费越来越贵了。因为在检查的过程中，医生只要把病人的情况输入进去，系统就会自动地提供需要检查的项目。本来一个普通的感冒，结果机器就建议病人做一个全方位的身体检查，这也就增加了无效、重复检查的几率。</p><p>再比如，很多软件里都有猜你喜欢的功能，像现在的购物网站，都会经常根据你的搜索历史，推荐你可能需要的东西。最极端的就是优衣库的选衣服系统，这个系统可以依靠大量的数据帮你选择，比如根据调查数据，将T恤按风格颜色分类，分别代表不同的心情，比如绿色代表冷静，接着，顾客会戴上能监测脑波的耳机，系统测试他们在观看代表不同心情的视频时的脑部活动。最后系统根据测试结果为顾客选择最符合他们心情的T恤。虽然这些是小事情，但这样其实是帮助你做一个个决定，这种推送看上去是帮我们在筛选更贴近我们喜好的产品，但是我们真正可选择的范围缩小了，因为自动化已经提前帮我们做了决定。</p><p>第三点，自动化会钝化我们的思维。</p><p>前面我们说了，自动化的出现，让我们不再需要直接做很多事情，只要盯着屏幕就可以了，但是我们的学习其实是有“生成效应”的，就是比起别人直接给我们的信息，我们对自己创造的信息记忆更牢固。就比如说自己造的句子，就比书上直接给我们的句子要印象更深刻，我们自己做出来的答案，就比抄别人的记得更牢固。也就是说，我们积极思考并动手完成一项任务的时候，更容易掌握相关知识和技能。这个技能越积累越多，我们的技能库存就越来越大。</p><p>之前我们学习的时候，可能是眼睛看、耳朵听、嘴巴里还重复着老师教给我们的知识，手上写了笔记，但是现在有了自动化的介入，很多时候我们只需要用眼睛看就可以了，做笔记也是在电子屏上选中、划线就可以了。这就让我们的感官利用越来越少，用得越少，退化就越严重。这种学习方式，容易让我们失去很多隐性知识，因为思维生成的时候是需要深层次地加工的。</p><p>再比如我们的计算能力，现在几乎已经退化得无影无踪了。以前受过基础教育的人，至少都能进行一些简单的心算，而现在再简单的计算都要用计算器。那你可能会说，有计算器当然就得用计算器了，又快又准，难不成还要退回到以前，对先进的工具视而不见吗？</p><p>作者不是这个意思，他的意思是说，常规的数学计算能力，可以培养起我们用数学思考的思维方式，它不单纯是计算能力，比如说看到某个事情，如果首先考虑到概率，那就是一种比较高级的思维方式。你如果用计算器，虽然只需按照要求输入数字和运算符号就能得出结果，省时省力，还比用手算的正确率高，但是用计算器输入进去的都是碎片化的数字，相互之间没有整体感，你和数字之间就很难建立起来联系。</p><p>第四点，自动化还有未解决的道德问题。</p><p>咱们说了自动化这么强大的功能，甚至能够代替我们做出决策，但是有一点它们是很难实现的，就是没有它自己的道德判断。一些我们觉得困难的事情，比如说同步翻译、快速匹配、数据分析、批量交易，对它们来说太简单了。但我们觉得很容易做到的事情，比如情绪、情感表达、道德判断，这些对自动化来说，就很难实现了。</p><p>比如说现在特别火的自动驾驶，各大制造商也开始研发各种自动驾驶的周边产品。但是在2015年5月美国布鲁金斯学会的无人驾驶研讨会上，有专家就曾提出了这样一个问题：如果无人驾驶汽车为了保护乘客而急刹车，但是急刹车会伤害旁边的路人，那无人驾驶到底应该如何做？然后机器的道德失误，应该去责怪谁呢，到底是生产商、设计者，还是销售商、购买者？</p><p>设想一下，如果现在我开着车行驶在路上，路上有一个失控的大卡车往我这边来了，我得赶紧转到旁边一个小胡同里躲避一下，在小胡同里已经停着一辆车了，车上没人，我必须得撞上小车才能保证自己不被大卡车碾压。但是这个时候自动驾驶的防撞系统检测到我要撞到障碍物了，于是就刹车了，我就得重新启动手动驾驶功能继续躲避，或者就得眼看着大卡车朝我冲过来。</p><p>我们再把脑洞开得大一点，假如有恐怖分子命令人工智能的机器人伤害无辜的人，那这些机器人到底是应该完全遵循主人的意志，还是应该抗命？</p><p>我们说了这么多应该警惕自动化，但是我们又生活在科技飞跃的时代里，不可避免地会用到，总不能回归原始人的生活吧。那到底该怎么办？在这里作者虽然没有给我们具体的做法，但可以从坚持工作、把自动化与人工操作相结合两个方面来保持清醒。</p><p>有一个工作悖论实验，跟踪5家公司的100名员工每天的状态，主要是看看他们怎么样度过工作时间和工作后的时间，以及这些活动带给了他们什么样的体验。实验结果出来之后，相比着空闲的阶段，实验人员发现，在工作期间，人们更加高兴，情绪更高。可能咱们觉得这个挺意外的，因为盼着下班、盼着放假基本都是人之常情，按理说大家都会喜欢休息和悠闲，但是为什么在这个时间大家的情绪反而比较低沉呢？这100个人说，虽然工作不是自己最喜欢的事情，但是在工作中，时间是充实的，并且工作有了成果会让人有成就感。休息时间，如果有可以做的事情还好，但是如果一点事情也没有的话，或者是把喜欢的事情做完以后，就会觉得特别无聊。</p><p>前面咱们说了如果只依靠自动化就会慢慢丧失掉我们自己的技能，所以在自动化开发和操作的时候，把人的操作也融合进去。比如让自动化软件定时地回到手动操控模式，为了随时接手，让操作员保持警觉；也可以把自动化操控设定在某个范围内，确保重要的、需要决策的任务由人脑来执行。</p><p>就比如说波音航空公司和空客公司，它们两家在设计自己飞机的时候就是不一样的策略。空客就是以无人驾驶为终极目标，认为客机造成空难很大一部分是因为驾驶人员的失误所导致的，因为人无完人，所以在空客的程序中，在特定的情况下，计算机可以推翻驾驶员的指令，换句话说，飞机的最终驾驶权是在计算机手里的。波音公司就不一样了，它们奉行“人定胜天”的原则，在设计的时候，一直体现着驾驶员对飞机的决策权。虽然现在看来这两家的安全记录差不多，但是最近以来，美国联邦航空管理局开始鼓励驾驶员更加深入地参与到飞行中，发挥自己本来的作用。</p><p>总结一下，这本书可以说是给我们对于技术的乐观打了一针镇静剂，让我们看到过度依赖使用自动化会让我们的技能退化、失去决策能力、钝化我们的思维。但想要完全脱离自动化的生活是不可能也是没必要的，我们需要的是保持清醒，保持清醒的办法主要是坚持自己的工作，把自动化与人工操作相结合。</p><p>自动化本身是没错的，但问题在于，我们不知道该在什么时间说“够了”，不知道自动化和人工的界限应该在哪里。计算机给我们造成安全假象时，很容易让我们对自动化产生过度依赖。虽然自动化让我们走进了一个看不见的笼子，但是我们仍然可以在自己喜欢做的事情中找到自己，找到不能被自动化代替的部分。比如说一名作家，他永远不能被文章生成器替代，因为无法表达出他要的意境；一名医生，不能被机器代替，因为病人很微小的症状，都是需要医生去询问、去观察，用丰富的经验去判断的；一位设计师的作品，不能被软件包办，因为每个设计都有自己的特点。</p><p>我们缺少的是保持思维的清醒、保持不被自动化推着走的能力，而我们要做的是重新判断，这些技术是增强了我们还是削弱了我们的核心能力，然后做出正确的选择。</p><p>撰稿：张凯 脑图：摩西 转述：孙潇</p>`,70))])}const C=A(d,[["render",u]]);export{q as __pageData,C as default};
